<!DOCTYPE html>
<html>
<head>
    <title>EDGE Data Pipeline – Jarvis Richard</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>

<body>
<div id="wrapper">

    <!-- Header -->
    <header id="header">
        <a href="index.html" class="logo">Jarvis Richard</a>
    </header>

    <!-- Nav -->
    <nav id="nav">
        <ul class="links">
            <li><a href="index.html">About</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
        <ul class="icons">
            <li><a href="https://www.linkedin.com/in/jarvisrichard/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
            <li><a href="https://github.com/jarvisrichard21" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
        </ul>
    </nav>
  <!-- Main -->
    <div id="main">

        <section class="post">
            <header class="major">
             <h1>EDGE Data Project – Part 1: ETL Pipeline</h1>
             <p>This section documents the full ETL process used to transform the five Memphis EDGE datasets into a clean, structured PostgreSQL database.</p>
            </header>
   
              <h2>ETL Overview</h2>
<p>ETL is a data engineering process that moves raw information from its original source into a clean, structured system where it can be analyzed.
<strong>It involves three stages: extracting data from external sources, transforming it through cleaning and standardization, and loading it into a database or warehouse.</strong> 
The result is a reliable pipeline of high‑quality data that can support analytics, reporting, dashboards, and other data‑driven products.</p>
        
            
      <h2>Extracting Data From External Sources</h2>

<p>
The extraction phase focused on locating and downloading the five EDGE program files from the Memphis Open Data Portal and preparing them for the next stage of the pipeline. At this point, the goal was simply to gather the raw data and verify that each file could be opened, inspected, and passed forward for transformation.
</p>

<h3>Challenges</h3>
<ul>
    <li><strong>ArcGIS‑generated structures:</strong> The source files used ArcGIS conventions that did not align cleanly with PostgreSQL expectations.</li>
    <li><strong>Early signs of schema inconsistencies:</strong> Field names, formats, and data types varied across programs, signaling the need for later standardization.</li>
</ul>

<h3>Solution</h3>
<ul>
    <li>I downloaded each dataset, inspected the raw structure, and documented the schema issues that would need to be addressed during the transformation phase. No restructuring occurred here — the goal was to capture the data exactly as provided and prepare it for systematic cleaning later.</li>
</ul>

<h3>Why This Step Mattered</h3>
<p>
A clean extraction ensures that the pipeline begins with complete, unaltered source data. By validating the files early and identifying structural issues without modifying them, I created a reliable foundation for the transformation work that follows. This separation of concerns keeps the ETL process organized, reproducible, and easier to debug.
</p>
                
         <h2>Transforming the Raw Data</h2>

<p>
The transformation phase focused on cleaning, standardizing, and restructuring the raw EDGE datasets so they could be loaded into PostgreSQL without errors. This step required rewriting schemas, converting ArcGIS-specific field types, and resolving inconsistencies across the five program files. The goal was to create a consistent, analysis-ready structure while preserving the integrity of the original data.
</p>

<h3>Challenges</h3>
<ul>
    <li><strong>Incompatible data types:</strong> Several fields used ArcGIS-specific types that PostgreSQL could not interpret.</li>
    <li><strong>Schema mismatches:</strong> Field names, formats, and table structures varied across programs, preventing a clean import.</li>
    <li><strong>Logical inconsistencies:</strong> Misspellings, malformed entries, and unnecessary fields appeared throughout the raw files.</li>
    <li><strong>Currency formatting issues:</strong> Monetary values included symbols and commas, blocking type conversion.</li>
</ul>

<h3>Solution</h3>
<ul>
    <li>I rewrote the table schemas to replace ArcGIS-specific field types with standard PostgreSQL types and aligned the structure of each dataset with a consistent schema pattern.</li>
    <li>I standardized geographic fields (ZIP code, state, city, county) and corrected inconsistent spellings and malformed entries.</li>
    <li>I removed formatting characters from currency fields to ensure they could be converted into numeric types.</li>
    <li>I eliminated unnecessary or redundant fields to improve clarity and reduce noise in the final dataset.</li>
</ul>

<h3>Why This Step Mattered</h3>
<p>
Transformation is the most critical phase of the ETL pipeline. Without standardizing data types, fixing schema mismatches, and resolving inconsistencies, PostgreSQL would reject the files during loading or produce unreliable analytical results. By completing these transformations up front, I ensured that the final database would be clean, consistent, and ready for accurate analysis.
</p>
            
        
             <h2>What Comes Next</h2>   
              <p>With the cleaned and standardized data now stored in PostgreSQL, the next phase of the project will focus on analysis. 
            I plan to explore how financial incentives influence job creation, industry growth, and investment patterns across Memphis. 
            This will include building analytical reports, visualizations, and dashboards that highlight the economic impact of EDGE programs.</p>  

             <hr/>   
            <div class="nav-bottom">
               <a href="edge.html" class="nav-left">← Back to Project Overview</a>
               <a href="edge_part2.html" class="nav-right">Part 2: Analysis/Visuals→</a>
          </div>
           </section>
    </div> <!-- closes #main -->

</div> <!-- closes #wrapper -->

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html> 


            
            

            
            
            
    
