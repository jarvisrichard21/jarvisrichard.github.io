<!DOCTYPE html>
<html>
<head>
    <title>EDGE Data Pipeline – Jarvis Richard</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>

<body>
<div id="wrapper">

    <!-- Header -->
    <header id="header">
        <a href="index.html" class="logo">Jarvis Richard</a>
    </header>

    <!-- Nav -->
    <nav id="nav">
        <ul class="links">
            <li><a href="index.html">About</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
        <ul class="icons">
            <li><a href="https://www.linkedin.com/in/jarvisrichard/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
            <li><a href="https://github.com/jarvisrichard21" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
        </ul>
    </nav>
  <!-- Main -->
    <div id="main">

        <section class="post">
            <header class="major">
             <h1>EDGE Data Project – Part 1: ETL Pipeline</h1>
             <p>This section documents the full ETL process used to transform the five Memphis EDGE datasets into a clean, structured PostgreSQL database.</p>
            </header>
   
              <h2>ETL Overview</h2>
<p>ETL is a data engineering process that moves raw information from its original source into a clean, structured system where it can be analyzed.
<strong>It involves three stages: extracting data from external sources, transforming it through cleaning and standardization, and loading it into a database or warehouse.</strong> 
The result is a reliable pipeline of high‑quality data that can support analytics, reporting, dashboards, and other data‑driven products.</p>
        
            
      <h2>Extracting Data From External Sources</h2>

<p>
The extraction phase focused on locating and downloading the five EDGE program files from the Memphis Open Data Portal and preparing them for the next stage of the pipeline. At this point, the goal was simply to gather the raw data and verify that each file could be opened, inspected, and passed forward for transformation.
</p>

<h3>Challenges</h3>
<ul>
    <li><strong>ArcGIS‑generated structures:</strong> The source files used ArcGIS conventions that did not align cleanly with PostgreSQL expectations.</li>
    <li><strong>Early signs of schema inconsistencies:</strong> Field names, formats, and data types varied across programs, signaling the need for later standardization.</li>
</ul>

<h3>Solution</h3>
<ul>
    <li>I downloaded each dataset, inspected the raw structure, and documented the schema issues that would need to be addressed during the transformation phase. No restructuring occurred here — the goal was to capture the data exactly as provided and prepare it for systematic cleaning later.</li>
</ul>

<h3>Why This Step Mattered</h3>
<p>
A clean extraction ensures that the pipeline begins with complete, unaltered source data. By validating the files early and identifying structural issues without modifying them, I created a reliable foundation for the transformation work that follows. This separation of concerns keeps the ETL process organized, reproducible, and easier to debug.
</p>
                
         <hr/>
        <h2>Technical Details</h2>
        <ul>
            <li>Standardized geographic fields (ZIP code, state, city, county) were cleaned and validated.</li>
            <li>Currency fields included symbols and commas, which prevented type conversion. I used Excel’s Find and Replace tool to strip formatting before loading.</li>
            <li>ArcGIS exports required schema redesign to align with PostgreSQL’s data types.</li>
        </ul>
         <hr/>
         <h2>Challenges & Solutions</h2>
            <h3>Inconsistent Naming Conventions</h3>
            <p>Each EDGE program used different field names and formats. I analyzed each table individually, identified shared fields, and created a structure that could support all five datasets without losing important details.</p>

            <h3>Schema mismatches from ArcGIS</h3>
            <p>ArcGIS exports didn’t align with PostgreSQL’s data types. I redesigned the schemas to ensure compatibility and consistency.</p>

            <h3>Currency formatting issues</h3>
            <p>Monetary values included symbols and commas. I removed these formatting characters before type conversion.</p>

            <h3>Logical errors and misspellings</h3>
            <p>I corrected inconsistent spellings, fixed malformed entries, and removed unnecessary fields to improve data quality.</p>

        <hr/>
            <h2>Data Modeling Concepts</h2>
            <p>The EDGE datasets are flat, meaning each table stands alone without primary keys, foreign keys, or hierarchical relationships. Even though some tables share similar attributes, they are not relationally linked and can be analyzed independently.</p>

             <figure class="image main">
                <img src="images/edge_ERD.png" alt="Entity relationship diagram showing the final PostgreSQL schema for the EDGE datasets"/>
                <figcaption>Figure 1. Final PostgreSQL schema for the EDGE datasets.</figcaption>
            </figure>


        <hr/>
             <h2>What Comes Next</h2>   
              <p>With the cleaned and standardized data now stored in PostgreSQL, the next phase of the project will focus on analysis. 
            I plan to explore how financial incentives influence job creation, industry growth, and investment patterns across Memphis. 
            This will include building analytical reports, visualizations, and dashboards that highlight the economic impact of EDGE programs.</p>  

             <hr/>   
            <div class="nav-bottom">
               <a href="edge.html" class="nav-left">← Back to Project Overview</a>
               <a href="edge_part2.html" class="nav-right">Part 2: Analysis/Visuals→</a>
          </div>
           </section>
    </div> <!-- closes #main -->

</div> <!-- closes #wrapper -->

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html> 


            
            

            
            
            
    
